Getting Started
================

Installation
-------------

`Installation <http://rouxcedr.github.io/post-hit/installation.html>`_

Running Post-Hit on a server
-----------------------------

In order to run Post-Hit locally or on a server you need to run *run.py* with python :

.. code-block:: sh

    python run.py

This should appear in the console : 

.. code-block:: sh
    
     * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)

Where 127.0.0.1:5000 is your server IP (Should be different if not running locally)

Post-Hit is now running on your server!.

Creating a new JSON dataset description
----------------------------------------

There is two way do create a new JSON dataset description :

    1. Write it yourself with this template

        .. code-block:: json

            {
              "dataset": {
                "resources": [
                  {
                    "id": "id",
                    "filename": "filename",
                    "download_link": "download link",
                    "description": ""
                  }
                ],
                "data_path": "",
                "project": "",
                "files_type": "",
                "version": 0,
                "description": "",
                "data_representation": {
                  
                },
                "project_link": "",
                "metadata": [
                  
                ],
                "protocole": ""
              }
            }

        Where the required parameters are:
            - **"resources"** is as list of dict containing the ID, filename, download_link and description of every file in the dataset. One dict is for one file.
            - **"data_path"** is the path where the files are to be stored or to be downloaded
            - **"file_type"** is the type of file in the dataset

                + **BigBed** : "bb"
                + **BigWig** : "bw"
                + **GTF** : "gtf" (must be compressed)
                + **CSV** : "csv"
                + **TSV** : "tsv"

            - **"protocole"** is the download protocole ("ftp" or "http")
            - **"data_representation"** is how you want the data to be represented after a query through the REST API :

                + For a `key-list representation <http://rouxcedr.github.io/post-hit/rest_api.html>`_ (see formated data) the dict is as folowed :

                    .. code-block:: json

                        {
                            "key": "",
                            "representation": "key-list",
                            "fields": [ "", "" ],
                            "chrom": "OPTIONAL (REQUIRED FOR CSV/TSV)",
                            "start": "OPTIONAL (REQUIRED FOR CSV/TSV)",
                            "end": "OPTIONAL (REQUIRED FOR CSV/TSV)"
                        }

                    With :

                        - **"representation"** always being "key-list"
                        - **"key"** location of the key (example : a column in the files "key" : "name" or a the ID in the JSON file "key" : "resource/id")
                        - **"fields"** being a list of column names where to get the information
                        - **"chrom", "start", "end"** being the names of the column in the files where the chromosome number, starting position and ending position are, respectively
            
        And the optional parameters but recommended are :
            - **"project"** is the project's name
            - **"description"** is the project's description
            - **"version"** is the dataset's version
            - **"project_link"** is the link to the project homepage
            - **"metadata"** : a list of dict containing the metadata for every ids/files in "resources"
    
    2. Load a `DataSet Class <http://rouxcedr.github.io/post-hit/rest_api.html>`_ :

        Copy this script in a new python file :
        
            .. code-block:: python

                #Fill out all the information needed to create the dataset (fields that are in caps)
                #To name the dataset use "find and replace" if your editor has it (ctrl-h) and replace DATASET_NAME with the name

                import sys
                
                #If needed put the post_hit package in you PYTHON_PATH like so :
                #sys.path.append("PATH_TO_POST_HIT_PACKAGE") 

                from post_hit.dataset import DataSet
                import os

                class DATASET_NAME(DataSet):
                    """docstring for GTEx"""
                    def __init__(self, dataset_path, data_path):

                        data_representation = {"representation" : "KEY-LIST OR VECTOR (REQUIRED)",
                                                "key": "KEY LOCATION (REQUIRED ONLY FOR KEY-LIST)",
                                                "fields": ["FIELDS (REQUIRED)"],
                                                "start": "START POSITION COLUMN NAME (REQUIRED ONLY FOR CSV/TSV)",
                                                "end": "START POSITION COLUMN NAME (REQUIRED ONLY FOR CSV/TSV)",
                                                "chrom": "START POSITION COLUMN NAME (REQUIRED ONLY FOR CSV/TSV)",
                                                }

                        ids = ["LIST OF IDS (Using a list comprehension is recommended)"]
                        filenames = ["LIST OF FILENAMES (Using a list comprehension is recommended)"]
                        download_links = ["LIST OF FILENAMES (Using a list comprehension is recommended)"]


                        metadata = ["LIST OF DICT CONTAINING THE METADATA FOR THE EVERY IDS/FILES (Using a list comprehension is recommended)"]
                        
                        kwarg = {
                            "project":  "PROJECT'S NAME(RECOMMENDED)",           
                            "description": "PROJECT'S DESCRIPTION (RECOMMENDED)",
                            "project_link": "PROJECT'S HOMEPAGE LINK (RECOMMENDED)",
                            "version": 1, #(RECOMMENDED)
                            "data_path": data_path,
                            "protocole": "DOWNLOAD PROTOCOL (REQUIRED)",
                            "file_type": "FILE TYPE (REQUIRED)",
                            "metadata": metadata,
                            "download_links": download_links,
                            "filenames":filenames,
                            "ids":ids,
                            "data_representation":data_representation
                            }

                        super(DATASET_NAME, self).__init__(dataset_path, **kwarg)

                def main():

                    dataset_path = os.path.dirname(__file__) + "/../DATASET_NAME.json"
                    data_path = os.path.dirname(__file__) + "/../../DATASET_NAME/"

                    
                    DATASET_NAME(dataset_path, data_path).create()

                if __name__ == '__main__':
                    main()

        Fill out the required fields as well as the recommended one if possible. Then run the script like so :

        .. code-block:: sh

            python filename.py




Query a region
---------------

In order to query the information of a region you need to use the `REST API <http://rouxcedr.github.io/post-hit/rest_api.html>`_.

The endpoint to be used is */region/<region>* where <region> is the region you want under the format **Chrom:Start-End**.

You then need to add the dataset you want to use for the query as so :

        url/region/<region> **?dataset=dataset1&dataset=dataset2&....**

Example : 
    
    - Request : http://127.0.0.1:5000/region/19:45826171-45826235?dataset=ensembl.json&dataset=gtex.json

    - Response : 
    
        .. code-block:: json

            {
                "response": [
                    {"ensembl": [
                        {"CKM": [
                            [{"feature": "gene"},
                                45809672,
                                45826235
                            ],
                            [{"feature": "transcript"},
                                45809672,
                                45826235
                            ],
                            [{"feature": "exon"},
                                45826079,
                                45826235
                            ],
                            [{"feature": "UTR"},
                                45826079,
                                45826235
                            ]
                        ]}
                    ]},
                    {"gtex": [
                        {"Muscle_Skeletal_Analysis": [
                            [{"gene_name": "MARK4",
                            "rs_id_dbSNP142_GRCh37p13": "rs344819"},
                                45823174,
                                45823174
                            ],
                            [{"gene_name": "MARK4",
                            "rs_id_dbSNP142_GRCh37p13": "rs344818"},
                                45823663,
                                45823663
                            ],
                            [{"gene_name": "MARK4",
                            "rs_id_dbSNP142_GRCh37p13": "rs6509208"},
                                45824218,
                                45824218
                            ],
                            [{"gene_name": "MARK4",
                              "rs_id_dbSNP142_GRCh37p13": "rs10410448"},
                                45825480,
                                45825480
                            ],
                            [{"gene_name": "MARK4",
                            "rs_id_dbSNP142_GRCh37p13": "rs344816"},
                                45825626,
                                45825626
                            ]
                        ]}
                    ]}
                ],
                "sucess": 1
            }
